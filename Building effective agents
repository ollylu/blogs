我们与各行各业构建大语言模型代理的数十个团队合作过，始终发现最成功的实现往往采用的是简单、可组合的模式，而不是复杂的框架。


过去一年里，Anthropic 与多个行业中构建大语言模型（LLM）代理的团队合作，发现最成功的案例并未依赖复杂框架或专用库，而是采用简单、可组合的设计模式。本文总结了他们与客户以及自身实践中的经验，为开发者提供构建高效代理的实用建议。

# What are agents?

“代理”一词有多种定义。有些用户将其视为能长时间独立运行、借助多种工具完成复杂任务的完全自主系统；也有用户用它来指代遵循预设流程的更具指导性的实现方式。Anthropic 将这类不同形式统称为“代理系统”（agentic systems），
但在架构上明确区分了“工作流”（workflows）与“代理”（agents）。


工作流（Workflows）是通过预定义的代码路径来协调大语言模型（LLM）与工具运行的系统；
而代理（Agents）则是由 LLM 自主动态引导其执行流程和工具使用方式，控制任务的完成方式。

接下来，文章将详细探讨这两类代理系统（工作流和代理）。在附录一《实际中的代理》中，作者还介绍了两个行业领域，说明客户在这些场景中使用代理系统取得了显著价值。

# When (and when not) to use agents

构建基于大语言模型（LLM）的应用时，Anthropic 建议尽量选择最简单的解决方案，只有在确实有需要时才增加系统复杂性。在很多情况下，甚至无需构建代理系统。代理系统通常以更高的延迟和成本，换取更优的任务表现，因此需要权衡是否值得这样做。

当任务需求更复杂时，工作流适用于结构清晰、步骤明确的任务，因其具备良好的可预测性和一致性。而当需要大规模的灵活处理和由模型驱动的决策时，代理则更合适。不过，对于很多应用场景，仅通过检索和上下文示例优化单次 LLM 调用，往往已经足够高效。

# When and how to use frameworks

有多种框架可以简化代理系统的实现，例如：
    LangChain 的 LangGraph、
    Amazon Bedrock 的 AI Agent 框架、
    拖拽式界面的 Rivet，
    以及用于构建和测试复杂工作流的 Vellum 等 GUI 工具。
这些框架有助于快速搭建系统，但选择时应考虑实际需求与系统复杂性。


这些框架简化了与 LLM 调用、工具定义、调用链接等标准任务的实现，便于快速入门。然而，它们通常引入额外的抽象层，可能掩盖底层提示和响应，导致调试变得更加困难。
此外，它们可能让人倾向于增加复杂性，而在某些情况下，简单的配置已经足够使用。

我们建议开发者首先直接使用 LLM API：许多模式只需要几行代码即可实现。如果确实使用框架，确保理解底层代码。对底层实现的错误假设是客户常见的错误来源。

# Building blocks, workflows, and agents

在这一节中，我们将探讨在生产环境中常见的代理系统模式。我们从基础构建块——增强型 LLM 开始，逐步增加复杂性，从简单的组合工作流到自主代理系统。

1、构建块：增强型 LLM

代理系统的基本构建块是通过检索、工具和记忆等增强功能扩展的大语言模型（LLM）。当前的模型能够主动利用这些能力，例如生成自己的搜索查询、选择合适的工具以及决定保留哪些信息。

我们建议关注实现的两个关键方面：将这些增强功能量身定制以适应特定用例，并确保为 LLM 提供一个简单且文档齐全的接口。
尽管实现这些增强功能有多种方式，一种方法是通过我们最近发布的“模型上下文协议”，它允许开发者通过简单的客户端实现与日益增长的第三方工具生态系统集成。
我们假设接下来每个 LLM 调用都可以访问这些增强功能。

2、工作流：提示链
提示链将任务分解为一系列步骤，每个 LLM 调用处理前一个调用的输出。你可以在任何中间步骤添加程序化检查（见下图中的“门”），以确保流程按预期进行。

何时使用此工作流：这种工作流非常适合将任务轻松且清晰地分解为固定子任务的情况。其主要目的是通过将每个 LLM 调用转化为更简单的任务，从而以牺牲延迟为代价，换取更高的准确性。

提示链在以下场景中非常有用：

   生成营销文案，然后将其翻译成不同语言。

   编写文档大纲，检查大纲是否符合特定标准，然后根据大纲编写文档。

3、工作流：路由
路由将输入分类并将其引导到专门的后续任务。这个工作流可以实现关注点分离，并构建更专业化的提示。如果没有这个工作流，优化某种类型的输入可能会对其他输入的性能产生负面影响。

何时使用该工作流：
当任务较复杂，且可以明确划分为适合分别处理的不同类别时，路由工作流特别有效。如果这些类别能够被准确分类（无论是通过 LLM 还是传统分类模型/算法），这种方式就非常适用。

路由工作流适用示例：

将不同类型的客户服务请求（如一般咨询、退款请求、技术支持）分别引导到对应的处理流程、提示词和工具。

将简单/常见的问题交由小模型（如 Claude 3.5 Haiku）处理，而将困难/不常见的问题交由更强大的模型（如 Claude 3.5 Sonnet）处理，以优化成本和响应速度。

4、“并行化”工作流
在“并行化”工作流中，大语言模型（LLMs）可以同时处理任务的多个部分，然后通过程序将结果合并。这种模式通常有两种主要形式：一种用于加速任务执行，另一种用于提升输出的质量。
在并行化工作流中，LLMs 可以同时处理任务的不同部分，然后将结果整合。主要有两种方式：

分段处理（Sectioning）：将任务拆分为独立的子任务并行执行。

投票机制（Voting）：对同一任务执行多次，生成不同输出，再进行比较或选择最优答案。

该并行化工作流适用于以下情况：当任务可以被拆分为可并行处理的子任务，以提高处理速度；或者当需要多种视角或多次尝试，以获得更高置信度的结果时。
对于需要多方面考量的复杂任务，让每个模型调用专注处理一个特定方面，通常会提升整体表现。
并行化适用的示例：

分段处理（Sectioning）：

实施保护机制时，一个模型实例处理用户请求，另一个模型实例同时筛查是否包含不当内容或请求。相比让同一个 LLM 同时负责筛查和回应，这种分工通常效果更好。

自动化评估 LLM 性能时，每个模型调用评估模型在某一提示上的不同表现维度。

投票机制（Voting）：

对一段代码进行漏洞审查时，可使用多个不同的提示分别分析代码，若其中任一提示发现问题即发出警报。

判断某段内容是否不当时，可使用多个提示从不同角度评估，或设定不同的投票门槛，以平衡误报与漏报的风险。

5、 调度器-工作者（Orchestrator-Workers）

在“调度器-工作者（Orchestrator-Workers）”工作流中，一个中央的 LLM 作为调度者，会动态地将复杂任务拆分为多个子任务，分派给不同的工作者 LLM来执行各个子任务，最后再由调度者汇总这些结果，形成完整的输出。

这种结构适用于复杂、需多步推理或多角度分析的任务，具备较强的灵活性与可扩展性。

这类工作流特别适用于复杂且无法预先确定子任务结构的任务。例如在编程场景中，具体需要修改的文件数量及每个文件的修改内容，往往取决于输入任务的具体要求。
虽然从结构上看它与“并行化”工作流相似，但核心区别在于灵活性：子任务不是预设好的，而是由调度器 LLM 根据实际输入动态决定。

调度器-工作者工作流的适用示例：

编程产品：每次需要对多个文件进行复杂更改时，调度器-工作者模式非常有用。

搜索任务：涉及从多个来源收集和分析信息以寻找相关内容时，这种工作流也能发挥重要作用。

6、评估器-优化器
在“评估器-优化器”工作流中，一个 LLM 调用生成响应，而另一个 LLM 在一个循环中提供评估和反馈，以持续改进结果。

何时使用此工作流：
当我们有明确的评估标准，并且通过迭代优化能带来可衡量的价值时，评估器-优化器工作流特别有效。
适合使用此工作流的两个标志是：
   一是 LLM 的响应在收到人工反馈后能够得到显著改进；
   二是 LLM 能够提供这种反馈。这与人类作家在撰写精炼文档时的迭代过程类似。

评估器-优化器适用的示例：

文学翻译：翻译 LLM 可能最初无法捕捉到某些细微差别，但评估器 LLM 可以提供有价值的批评意见，以帮助改进翻译。

复杂搜索任务：需要多轮搜索和分析以收集全面信息，评估器决定是否需要进行进一步的搜索。

7、Agents

随着 LLM 在关键能力上逐步成熟——如理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复——代理系统在生产环境中逐渐崭露头角。
代理开始时通过人类用户的命令或互动讨论来启动任务。一旦任务明确，代理就能独立规划和执行，可能会返回向人类请求更多信息或判断。
在执行过程中，代理需要从环境中获得“真实数据”，例如工具调用结果或代码执行，以评估进展。当遇到障碍或需要反馈时，代理可以暂停等待人类的意见。
任务通常在完成后终止，但也常会设有停止条件（如最大迭代次数）以保持控制。

代理可以处理复杂任务，但它们的实现通常很简单。代理通常是基于环境反馈循环使用工具的 LLM。
因此，设计工具集及其文档时，必须清晰而周到。在附录 2（“工具提示工程”）中，我们进一步探讨了工具开发的最佳实践。

何时使用代理：
代理适用于那些难以或无法预测所需步骤数的开放性问题，且无法硬编码固定路径的情况。LLM 可能需要多轮操作，因此必须对其决策过程有一定信任。
代理的自主性使其非常适合在可信环境中扩展任务。

代理的自主性意味着更高的成本，并且可能导致错误的积累。因此，我们建议在沙箱环境中进行广泛测试，并设置适当的保护措施以确保安全。

代理适用的示例：

以下是我们自己实现的示例：

一个用于解决 SWE-bench 任务的编码代理，该任务涉及根据任务描述编辑多个文件；

我们的“计算机使用”参考实现，Claude 使用计算机完成任务。

结合与定制这些模式
这些构建模块并不是固定的指导方针。它们是开发人员可以根据不同的用例进行调整和组合的常见模式。
成功的关键与任何 LLM 功能一样，都是衡量性能并对实现进行迭代。再次强调：只有当增加复杂性显著改善结果时，才应考虑这样做。

总结
LLM 领域的成功并不在于构建最复杂的系统，而在于为您的需求构建合适的系统。
从简单的提示开始，通过全面的评估来优化它们，仅在更简单的解决方案无法满足需求时，才添加多步骤的代理系统。

在实现代理时，我们尝试遵循三个核心原则：

保持代理设计的简洁性。

优先考虑透明度，明确展示代理的规划步骤。

通过彻底的工具文档和测试，精心设计代理-计算机接口（ACI）。

框架可以帮助你快速入门，但在进入生产阶段时，不要犹豫减少抽象层次，并使用基本组件来构建。通过遵循这些原则，你可以创建不仅强大，而且可靠、易维护、并且用户信任的代理系统。

